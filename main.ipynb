{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo para identificação de pessoas e captura da cor de suas roupas usando apenas métodos de visão computacional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Abrir o vídeo\n",
    "cam = cv.VideoCapture(\"./video1.mp4\")\n",
    "\n",
    "# Inicializar variáveis para histórico de pessoas detectadas\n",
    "people_detected = []\n",
    "person_id = 0\n",
    "false_id = 500000\n",
    "TIMEOUT = 25  # Número de frames até considerarmos que a pessoa saiu\n",
    "DETECTION_DELAY = 100  # Número de frames para considerar uma nova pessoa\n",
    "paused = False\n",
    "prev_time = time.time()\n",
    "orb = cv.ORB_create()\n",
    "\n",
    "# Ler o primeiro frame como referência de fundo\n",
    "ret, frame_reference = cam.read()\n",
    "if not ret:\n",
    "    print(\"Erro ao carregar o vídeo\")\n",
    "    cam.release()\n",
    "    exit()\n",
    "\n",
    "\n",
    "frame_reference_gray = cv.cvtColor(frame_reference, cv.COLOR_BGR2GRAY)\n",
    "frame_reference_gray = cv.GaussianBlur(frame_reference_gray, (31, 31), 0)\n",
    "\n",
    "COLOR_NAMES = {\n",
    "    'preto': (0, 0, 0),\n",
    "    'branco': (255, 255, 255),\n",
    "    'cinza escuro': (64, 64, 64),\n",
    "    'cinza': (128, 128, 128),\n",
    "    'cinza claro': (192, 192, 192),\n",
    "    'vermelho': (255, 0, 0),\n",
    "    'verde': (0, 255, 0),\n",
    "    'azul': (0, 0, 255),\n",
    "    'amarelo': (255, 255, 0),\n",
    "    'ciano': (0, 255, 255),\n",
    "    'magenta': (255, 0, 255),\n",
    "    'laranja': (255, 165, 0),\n",
    "    'rosa': (255, 192, 203),\n",
    "    'roxo': (128, 0, 128),\n",
    "    'marrom': (165, 42, 42),\n",
    "    'azul claro': (173, 216, 230),\n",
    "    'verde claro': (144, 238, 144),\n",
    "    'vermelho claro': (255, 102, 102),\n",
    "    'amarelo claro': (255, 255, 153),\n",
    "    'laranja escuro': (255, 140, 0),\n",
    "    'roxo claro': (216, 191, 216),\n",
    "    'azul escuro': (0, 0, 139),\n",
    "    'verde escuro': (0, 100, 0),\n",
    "    'vermelho escuro': (139, 0, 0),\n",
    "    'dourado': (255, 215, 0),\n",
    "    'prata': (192, 192, 192),\n",
    "    'champanhe': (247, 231, 206),\n",
    "    'violeta': (238, 130, 238),\n",
    "    'salmão': (250, 128, 114),\n",
    "    'menta': (189, 252, 201),\n",
    "    'lavanda': (230, 230, 250),\n",
    "    'azul marinho': (0, 0, 128),\n",
    "    'verde oliva': (107, 142, 35),\n",
    "    'bege': (245, 245, 220),\n",
    "    'turquesa': (64, 224, 208),\n",
    "    'marfim': (255, 255, 240)\n",
    "}\n",
    "\n",
    "\n",
    "# Função para calcular o histograma de cores de um ROI\n",
    "def get_color_histogram(roi):\n",
    "    hist = cv.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    return cv.normalize(hist, hist).flatten()\n",
    "\n",
    "\n",
    "# Função para calcular a distância euclidiana entre cores\n",
    "def euclidean_distance(color1, color2):\n",
    "    return np.sqrt(np.sum((np.array(color1) - np.array(color2)) ** 2))\n",
    "\n",
    "# Função para encontrar o nome da cor mais próxima\n",
    "def get_color_name(mean_color):\n",
    "    closest_color = None\n",
    "    min_distance = float('inf')\n",
    "    for color_name, color_value in COLOR_NAMES.items():\n",
    "        dist = euclidean_distance(mean_color[:3], color_value)  # Ignorar o canal alpha (transparência)\n",
    "        if dist < min_distance:\n",
    "            min_distance = dist\n",
    "            closest_color = color_name\n",
    "    return closest_color\n",
    "\n",
    "\n",
    "def get_median_color(roi_contour, mask):\n",
    "    # Extraímos as cores do ROI usando a máscara\n",
    "    roi_colors = roi_contour[mask == 255]  # Pega apenas os pixels dentro da máscara\n",
    "    if roi_colors.size == 0:\n",
    "        return (0, 0, 0)  # Retorna preto se não houver pixels válidos\n",
    "\n",
    "    # Calcula a mediana para cada canal (B, G, R)\n",
    "    median_color = np.median(roi_colors, axis=0)\n",
    "    return median_color\n",
    "\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "        frame_gray = cv.GaussianBlur(frame_gray, (31, 31), 0)\n",
    "\n",
    "        # Subtrair o frame de referência do frame atual\n",
    "        frame_delta = cv.absdiff(frame_reference_gray, frame_gray)\n",
    "        _, thresh = cv.threshold(frame_delta, 25, 255, cv.THRESH_BINARY)\n",
    "        thresh = cv.dilate(thresh, None, iterations=2)\n",
    "        \n",
    "        colored_movement = cv.bitwise_and(frame, frame, mask=thresh)\n",
    "\n",
    "        # Encontrar contornos\n",
    "        contours, _ = cv.findContours(thresh.copy(), cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filtrar contornos pequenos e criar uma lista de áreas\n",
    "        valid_contours = []\n",
    "        areas = [cv.contourArea(contour) for contour in contours if cv.contourArea(contour) >= 1000]\n",
    "\n",
    "        if areas:\n",
    "            max_area = max(areas)\n",
    "\n",
    "            for contour in contours:\n",
    "                area = cv.contourArea(contour)\n",
    "                if area >= 1000 and area > max_area * 0.3:\n",
    "                    valid_contours.append(contour)\n",
    "\n",
    "        # Loop sobre os contornos filtrados\n",
    "        for contour in valid_contours:\n",
    "            x, y, w, h = cv.boundingRect(contour)\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            person_hist = get_color_histogram(roi)\n",
    "\n",
    "            new_person = True\n",
    "            for person in people_detected:\n",
    "                dist = cv.compareHist(person['hist'], person_hist, cv.HISTCMP_CORREL)\n",
    "                if dist > 0.8:\n",
    "                    person['last_seen'] = (x, y)\n",
    "                    person['missed_frames'] = 0\n",
    "                    person['detection_delay'] += 1  # Incrementa o contador de frames para essa pessoa\n",
    "                    new_person = False\n",
    "                    \n",
    "                    # Se a pessoa já estiver detectada há mais de 3 segundos, capturar keypoints e descritores\n",
    "                    if time.time() - person['time_entered'] > 3:\n",
    "                        if person['false_id'] != 0: \n",
    "                            person_id += 1\n",
    "                            person[\"real_id\"] = person_id\n",
    "                        person['false_id'] = 0\n",
    "\n",
    "                        hull = cv.convexHull(contour)\n",
    "                        cv.drawContours(frame, [hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "                        kp = orb.detect(colored_movement, None) \n",
    "                        kp, des = orb.compute(colored_movement, kp)\n",
    "                        person['keypoints'] = kp[:person['num_descriptors']]\n",
    "                        person['descriptors'] = des[:person['num_descriptors']]\n",
    "                        person['num_descriptors'] += 10  # Aumenta o número de descritores capturados\n",
    "\n",
    "                        # Desenhar keypoints na imagem\n",
    "                        frame = cv.drawKeypoints(frame, kp, 0, (0, 0, 255), flags=cv.DRAW_MATCHES_FLAGS_NOT_DRAW_SINGLE_POINTS)\n",
    "                        cv.putText(frame, f\"Pessoa {person['real_id']} detectada\", (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                    # Adicionar o código para calcular a cor predominante dentro do contorno\n",
    "                    roi_contour = frame[y:y+h, x:x+w]\n",
    "                    mask = np.zeros_like(roi_contour)\n",
    "                    \n",
    "                    cv.drawContours(mask, [contour], -1, (255, 255, 255), thickness=cv.FILLED, offset=(-x, -y))\n",
    "                    median_color = get_median_color(roi_contour, mask[:, :, 0])\n",
    "                    median_color = [float(f\"{median_color[0]:.1f}\"), float(f\"{median_color[1]:.1f}\"), float(f\"{median_color[2]:.1f}\")]\n",
    "                    color_name = get_color_name(median_color)\n",
    "                    # cv.putText(frame, f\"Cor: {color_name}\", (x, y + 30), cv.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                    \n",
    "                    break\n",
    "\n",
    "            if new_person:\n",
    "                false_id += 1\n",
    "                people_detected.append({\n",
    "                    'false_id': false_id,\n",
    "                    'real_id': false_id,\n",
    "                    'hist': person_hist,\n",
    "                    'last_seen': (x, y),\n",
    "                    'missed_frames': 0,\n",
    "                    'detection_delay': 1,  # Inicia o contador para nova detecção\n",
    "                    'time_entered': time.time(),\n",
    "                    'num_descriptors': 10,  # Inicia com 10 descritores\n",
    "                    'keypoints': None,\n",
    "                    'descriptors': None\n",
    "                })\n",
    "\n",
    "        # Atualiza o contador de frames perdidos para todas as pessoas\n",
    "        for person in people_detected:\n",
    "            if person['missed_frames'] > TIMEOUT:\n",
    "                people_detected.remove(person)\n",
    "            else:\n",
    "                person['missed_frames'] += 1\n",
    "\n",
    "        current_time = time.time()\n",
    "        fps = 1 / (current_time - prev_time)\n",
    "        prev_time = current_time\n",
    "        \n",
    "        cv.putText(frame, f'FPS: {int(fps)}', (10, 30), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        \n",
    "        # Mostrar IDs de todas as pessoas detectadas recentemente\n",
    "        cv.imshow('Colored', colored_movement)\n",
    "        cv.imshow('frame delta', frame_delta)\n",
    "        cv.imshow('Deteccao de Mudancas', frame)\n",
    "\n",
    "    key = cv.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "# Liberar o vídeo e fechar as janelas\n",
    "cam.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmo para identificação de pessoas e captura da cor de suas roupas usando YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet ultralytics\n",
    "!pip install --quiet scikit-learn\n",
    "\n",
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "\n",
    "model = YOLO('yolov8n.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "cap = cv2.VideoCapture(\"./video2.mp4\")\n",
    "\n",
    "# Usa modelo da Yolo\n",
    "model = YOLO(\"yolov8n.pt\")  # Modelo leve para melhor desempenho\n",
    "\n",
    "track_history = defaultdict(lambda: [])\n",
    "person_id_counter = 0  # Contador de IDs de pessoas\n",
    "person_ids = {}  # Dicionário para mapear track_id para um person_id exclusivo\n",
    "\n",
    "seguir = True\n",
    "deixar_rastro = True\n",
    "\n",
    "frame_count = 0\n",
    "frame_skip = 2  # Ajuste o valor para pular mais frames e melhorar o desempenho\n",
    "\n",
    "# Iniciar o contador de tempo para o cálculo do FPS\n",
    "prev_time = time.time()\n",
    "\n",
    "# Reduz a resolução para aumentar o FPS (opcional)\n",
    "resize_width = 640\n",
    "resize_height = 360\n",
    "\n",
    "# Função para obter a cor predominante\n",
    "def get_dominant_color(image, box):\n",
    "    x, y, w, h = map(int, box)\n",
    "    person_roi = image[y - h // 2: y + h // 2, x - w // 2: x + w // 2]\n",
    "\n",
    "    if person_roi.size == 0:\n",
    "        return (0, 0, 0)  # Evitar erro se a ROI estiver vazia\n",
    "\n",
    "    # Redimensiona a imagem para facilitar o cálculo da cor dominante\n",
    "    person_roi = cv2.resize(person_roi, (50, 50), interpolation=cv2.INTER_AREA)\n",
    "    \n",
    "    # Converte a imagem para um array 2D de pixels\n",
    "    pixels = person_roi.reshape((-1, 3))\n",
    "    \n",
    "    # Usa o KMeans para encontrar a cor mais comum\n",
    "    kmeans = KMeans(n_clusters=1)\n",
    "    kmeans.fit(pixels)\n",
    "    \n",
    "    # A cor predominante será o centro do cluster\n",
    "    dominant_color = kmeans.cluster_centers_[0].astype(int)\n",
    "    \n",
    "    return tuple(map(int, dominant_color))  # Certifique-se de retornar inteiros\n",
    "\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "\n",
    "    if not success:\n",
    "        break  # Sai do loop se não conseguir ler mais frames\n",
    "\n",
    "    frame_count += 1\n",
    "    if frame_count % frame_skip != 0:\n",
    "        continue  # Pule este frame para melhorar o desempenho\n",
    "\n",
    "    # Redimensiona o frame para resolução menor\n",
    "    img = cv2.resize(img, (resize_width, resize_height))\n",
    "\n",
    "    # YOLOv8 Processamento\n",
    "    if seguir:\n",
    "        results = model.track(img, persist=True)\n",
    "    else:\n",
    "        results = model(img)\n",
    "\n",
    "    # Cria uma cópia da imagem original para desenhar apenas pessoas\n",
    "    img_people_only = img.copy()\n",
    "\n",
    "    # Processar a lista de resultados\n",
    "    for result in results:\n",
    "        if seguir and deixar_rastro:\n",
    "            try:\n",
    "                person_class_index = 0  # Índice da classe \"person\" na YOLOv8 é geralmente 0\n",
    "                boxes = result.boxes.xywh.cpu()\n",
    "                track_ids = result.boxes.id.int().cpu().tolist()\n",
    "                class_ids = result.boxes.cls.int().cpu().tolist()\n",
    "\n",
    "                # Desenha as caixas, IDs e rastros apenas para pessoas\n",
    "                for box, track_id, class_id in zip(boxes, track_ids, class_ids):\n",
    "                    if class_id == person_class_index:\n",
    "                        x, y, w, h = map(int, box)  # Certifique-se de que as coordenadas são inteiras\n",
    "\n",
    "                        # Atribui um novo person_id se ainda não estiver no dicionário\n",
    "                        if track_id not in person_ids:\n",
    "                            person_ids[track_id] = person_id_counter\n",
    "                            person_id_counter += 1\n",
    "\n",
    "                        person_id = person_ids[track_id]\n",
    "\n",
    "                        # Obtém a cor predominante da pessoa\n",
    "                        dominant_color = get_dominant_color(img, box)\n",
    "\n",
    "                        # Desenha o retângulo ao redor das pessoas\n",
    "                        cv2.rectangle(img_people_only, (x - w // 2, y - h // 2),\n",
    "                                      (x + w // 2, y + h // 2), (0, 255, 0), 2)\n",
    "\n",
    "                        # Adiciona o ID e a cor predominante na imagem perto do retângulo\n",
    "                        cv2.putText(img_people_only, f'ID: {person_id}', (x - w // 2, y - h // 2 - 10),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "                        cv2.putText(img_people_only, f'Cor BGR {dominant_color}', (x - w // 2, y - h // 2 - 30),\n",
    "                                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, ((dominant_color[0]), int(dominant_color[1]), int(dominant_color[2])), 2)\n",
    "\n",
    "                        # Rastreia o histórico de posição para cada pessoa\n",
    "                        track = track_history[track_id]\n",
    "                        track.append((float(x), float(y)))  # Ponto central x, y\n",
    "                        if len(track) > 30:  # Mantém no máximo 30 frames no histórico\n",
    "                            track.pop(0)\n",
    "\n",
    "                        # Desenha as linhas de rastreamento\n",
    "                        points = np.array(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "                        cv2.polylines(img_people_only, [points], isClosed=False, color=(230, 0, 0), thickness=5)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro: {e}\")\n",
    "                pass\n",
    "\n",
    "    # Calcula o FPS\n",
    "    current_time = time.time()\n",
    "    fps = 1 / (current_time - prev_time)\n",
    "    prev_time = current_time\n",
    "\n",
    "    # Desenha o FPS no canto da imagem\n",
    "    cv2.putText(img_people_only, f'FPS: {int(fps)}', (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Mostra a imagem filtrada com apenas pessoas\n",
    "    cv2.imshow(\"Frame\", img_people_only)\n",
    "\n",
    "    k = cv2.waitKey(1)\n",
    "    if k == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "print(\"desligando\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
