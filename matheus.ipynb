{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Abrir o vídeo\n",
    "cam = cv2.VideoCapture(\"./teste4.mp4\")\n",
    "\n",
    "# Ler o primeiro frame como referência de fundo\n",
    "ret, frame_reference = cam.read()\n",
    "if not ret:\n",
    "    print(\"Erro ao carregar o vídeo\")\n",
    "    cam.release()\n",
    "    exit()\n",
    "\n",
    "frame_reference = cv2.resize(frame_reference, (0, 0), fx=1, fy=1)\n",
    "frame_reference = cv2.flip(frame_reference, 1)\n",
    "frame_reference_gray = cv2.cvtColor(frame_reference, cv2.COLOR_BGR2GRAY)\n",
    "frame_reference_gray = cv2.GaussianBlur(frame_reference_gray, (31, 31), 0)\n",
    "\n",
    "# Inicializar variáveis para histórico de pessoas detectadas\n",
    "people_detected = []\n",
    "person_id = 0\n",
    "TIMEOUT = 50  # Número de frames até considerarmos que a pessoa saiu\n",
    "DETECTION_DELAY = 240  # Número de frames para considerar uma nova pessoa\n",
    "\n",
    "# Função para calcular o histograma de cores de um ROI\n",
    "def get_color_histogram(roi):\n",
    "    hist = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (0, 0), fx=1, fy=1)\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (31, 31), 0)\n",
    "\n",
    "    # Subtrair o frame de referência do frame atual\n",
    "    frame_delta = cv2.absdiff(frame_reference_gray, frame_gray)\n",
    "    _, thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filtrar contornos pequenos e criar uma lista de áreas\n",
    "    valid_contours = []\n",
    "    areas = [cv2.contourArea(contour) for contour in contours if cv2.contourArea(contour) >= 1000]\n",
    "\n",
    "    if areas:\n",
    "        max_area = max(areas)\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area >= 1000 and area > max_area * 0.3:\n",
    "                valid_contours.append(contour)\n",
    "\n",
    "    # Loop sobre os contornos filtrados\n",
    "    for contour in valid_contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        person_hist = get_color_histogram(roi)\n",
    "\n",
    "        new_person = True\n",
    "        for person in people_detected:\n",
    "            dist = cv2.compareHist(person['hist'], person_hist, cv2.HISTCMP_CORREL)\n",
    "            if dist > 0.8:\n",
    "                person['last_seen'] = (x, y)\n",
    "                person['missed_frames'] = 0\n",
    "                person['detection_delay'] += 1  # Incrementa o contador de frames para essa pessoa\n",
    "                new_person = False\n",
    "                break\n",
    "\n",
    "        if new_person:\n",
    "            # Adiciona nova pessoa apenas após o número definido de frames\n",
    "            if person_id < DETECTION_DELAY:\n",
    "                person_id += 1\n",
    "                people_detected.append({\n",
    "                    'id': person_id,\n",
    "                    'hist': person_hist,\n",
    "                    'last_seen': (x, y),\n",
    "                    'missed_frames': 0,\n",
    "                    'detection_delay': 1  # Inicia o contador para nova detecção\n",
    "                })\n",
    "                cv2.putText(frame, f\"Pessoa {person_id} detectada\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Se a nova pessoa ainda não tiver sido detectada por um tempo suficiente, apenas atualiza last_seen\n",
    "                cv2.putText(frame, \"Esperando por nova detecção...\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Desenhar a casca convexa ao redor da pessoa detectada\n",
    "        hull = cv2.convexHull(contour)\n",
    "        cv2.drawContours(frame, [hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Atualiza o contador de frames perdidos para todas as pessoas\n",
    "    for person in people_detected:\n",
    "        if person['missed_frames'] > TIMEOUT:\n",
    "            people_detected.remove(person)\n",
    "        else:\n",
    "            person['missed_frames'] += 1\n",
    "\n",
    "    # Mostrar IDs de todas as pessoas detectadas recentemente\n",
    "    for person in people_detected:\n",
    "        if person['missed_frames'] <= TIMEOUT:\n",
    "            cv2.putText(frame, f\"Pessoa {person['id']}\", person['last_seen'], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar o frame com as detecções\n",
    "    cv2.imshow('Deteccao de Mudancas', frame)\n",
    "    cv2.imshow('Thresh', thresh)\n",
    "    cv2.imshow('Frame Delta', frame_delta)\n",
    "\n",
    "    # Pressione 'q' para sair\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar o vídeo e fechar as janelas\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vídeo de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Abrir o vídeo\n",
    "cam = cv2.VideoCapture(\"./teste5.mp4\")\n",
    "\n",
    "# Ler o primeiro frame como referência de fundo\n",
    "ret, frame_reference = cam.read()\n",
    "if not ret:\n",
    "    print(\"Erro ao carregar o vídeo\")\n",
    "    cam.release()\n",
    "    exit()\n",
    "\n",
    "fast = cv2.FastFeatureDetector_create() \n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "frame_reference = cv2.resize(frame_reference, (0, 0), fx=1, fy=1)\n",
    "frame_reference = cv2.flip(frame_reference, 1)\n",
    "frame_reference_gray = cv2.cvtColor(frame_reference, cv2.COLOR_BGR2GRAY)\n",
    "frame_reference_gray = cv2.GaussianBlur(frame_reference_gray, (31, 31), 0)\n",
    "\n",
    "# Inicializar variáveis para histórico de pessoas detectadas\n",
    "people_detected = []\n",
    "person_id = 0\n",
    "false_id = 500000\n",
    "TIMEOUT = 25  # Número de frames até considerarmos que a pessoa saiu\n",
    "DETECTION_DELAY = 100  # Número de frames para considerar uma nova pessoa\n",
    "paused = False\n",
    "\n",
    "# Função para calcular o histograma de cores de um ROI\n",
    "def get_color_histogram(roi):\n",
    "    hist = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = cv2.resize(frame, (0, 0), fx=1, fy=1)\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray, (31, 31), 0)\n",
    "\n",
    "        # Subtrair o frame de referência do frame atual\n",
    "        frame_delta = cv2.absdiff(frame_reference_gray, frame_gray)\n",
    "        _, thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        \n",
    "        colored_movement = cv2.bitwise_and(frame, frame, mask=thresh)\n",
    "\n",
    "        # Encontrar contornos\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filtrar contornos pequenos e criar uma lista de áreas\n",
    "        valid_contours = []\n",
    "        areas = [cv2.contourArea(contour) for contour in contours if cv2.contourArea(contour) >= 1000]\n",
    "\n",
    "        if areas:\n",
    "            max_area = max(areas)\n",
    "\n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area >= 1000 and area > max_area * 0.3:\n",
    "                    valid_contours.append(contour)\n",
    "\n",
    "        # Loop sobre os contornos filtrados\n",
    "        for contour in valid_contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            person_hist = get_color_histogram(roi)\n",
    "\n",
    "            new_person = True\n",
    "            for person in people_detected:\n",
    "                dist = cv2.compareHist(person['hist'], person_hist, cv2.HISTCMP_CORREL)\n",
    "                if dist > 0.8:\n",
    "                    person['last_seen'] = (x, y)\n",
    "                    person['missed_frames'] = 0\n",
    "                    person['detection_delay'] += 1  # Incrementa o contador de frames para essa pessoa\n",
    "                    new_person = False\n",
    "                    \n",
    "                    # Se a pessoa já estiver detectada há mais de 3 segundos, capturar keypoints e descritores\n",
    "                    if time.time() - person['time_entered'] > 3:\n",
    "                        if person['false_id'] != 0: \n",
    "                            person_id += 1\n",
    "                            person[\"real_id\"] = person_id\n",
    "                        person['false_id'] = 0\n",
    "                        \n",
    "                        hull = cv2.convexHull(contour)\n",
    "                        cv2.drawContours(frame, [hull], -1, (0, 255, 0), 2)\n",
    "                        \n",
    "                        kp = fast.detect(colored_movement, None) \n",
    "                        # kp = orb.detect(colored_movement, None) \n",
    "                        kp, des = orb.compute(colored_movement, kp) \n",
    "                        person['keypoints'] = kp[:person['num_descriptors']]\n",
    "                        person['descriptors'] = des[:person['num_descriptors']]\n",
    "                        person['num_descriptors'] += 10  # Aumenta o número de descritores capturados\n",
    "\n",
    "                        # Desenhar keypoints na imagem\n",
    "                        # frame = cv2.drawKeypoints(frame, person['keypoints'], frame, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n",
    "                        cv2.putText(frame, f\"Pessoa {person['real_id']} detectada\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                    break\n",
    "\n",
    "            if new_person:\n",
    "                # person_id += 1\n",
    "                false_id += 1\n",
    "                people_detected.append({\n",
    "                    'false_id': false_id,\n",
    "                    'real_id': false_id,\n",
    "                    'hist': person_hist,\n",
    "                    'last_seen': (x, y),\n",
    "                    'missed_frames': 0,\n",
    "                    'detection_delay': 1,  # Inicia o contador para nova detecção\n",
    "                    'time_entered': time.time(),\n",
    "                    'num_descriptors': 10,  # Inicia com 10 descritores\n",
    "                    'keypoints': None,\n",
    "                    'descriptors': None\n",
    "                })\n",
    "                # cv2.putText(frame, f\"Pessoa {person_id} detectada\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Desenhar a casca convexa ao redor da pessoa detectada\n",
    "            # hull = cv2.convexHull(contour)\n",
    "            # cv2.drawContours(frame, [hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "        # Atualiza o contador de frames perdidos para todas as pessoas\n",
    "        for person in people_detected:\n",
    "            if person['missed_frames'] > TIMEOUT:\n",
    "                people_detected.remove(person)\n",
    "            else:\n",
    "                person['missed_frames'] += 1\n",
    "\n",
    "        # Mostrar IDs de todas as pessoas detectadas recentemente\n",
    "        # for person in people_detected:\n",
    "        #     if person['missed_frames'] <= TIMEOUT:\n",
    "        #         cv2.putText(frame, f\"Pessoa {person['false_id']}\", person['last_seen'], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Mostrar o frame com as detecções\n",
    "        # cv2.imshow('Thresh', thresh)\n",
    "        # cv2.imshow('Frame Delta', frame_delta)\n",
    "        cv2.imshow('Colored', colored_movement)\n",
    "        cv2.imshow('Deteccao de Mudancas', frame)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "# Liberar o vídeo e fechar as janelas\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
