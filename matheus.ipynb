{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Abrir o vídeo\n",
    "cam = cv2.VideoCapture(\"./teste4.mp4\")\n",
    "\n",
    "# Ler o primeiro frame como referência de fundo\n",
    "ret, frame_reference = cam.read()\n",
    "if not ret:\n",
    "    print(\"Erro ao carregar o vídeo\")\n",
    "    cam.release()\n",
    "    exit()\n",
    "\n",
    "frame_reference = cv2.resize(frame_reference, (0, 0), fx=1, fy=1)\n",
    "frame_reference = cv2.flip(frame_reference, 1)\n",
    "frame_reference_gray = cv2.cvtColor(frame_reference, cv2.COLOR_BGR2GRAY)\n",
    "frame_reference_gray = cv2.GaussianBlur(frame_reference_gray, (31, 31), 0)\n",
    "\n",
    "# Inicializar variáveis para histórico de pessoas detectadas\n",
    "people_detected = []\n",
    "person_id = 0\n",
    "TIMEOUT = 50  # Número de frames até considerarmos que a pessoa saiu\n",
    "DETECTION_DELAY = 240  # Número de frames para considerar uma nova pessoa\n",
    "\n",
    "# Função para calcular o histograma de cores de um ROI\n",
    "def get_color_histogram(roi):\n",
    "    hist = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (0, 0), fx=1, fy=1)\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (31, 31), 0)\n",
    "\n",
    "    # Subtrair o frame de referência do frame atual\n",
    "    frame_delta = cv2.absdiff(frame_reference_gray, frame_gray)\n",
    "    _, thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filtrar contornos pequenos e criar uma lista de áreas\n",
    "    valid_contours = []\n",
    "    areas = [cv2.contourArea(contour) for contour in contours if cv2.contourArea(contour) >= 1000]\n",
    "\n",
    "    if areas:\n",
    "        max_area = max(areas)\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area >= 1000 and area > max_area * 0.3:\n",
    "                valid_contours.append(contour)\n",
    "\n",
    "    # Loop sobre os contornos filtrados\n",
    "    for contour in valid_contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        person_hist = get_color_histogram(roi)\n",
    "\n",
    "        new_person = True\n",
    "        for person in people_detected:\n",
    "            dist = cv2.compareHist(person['hist'], person_hist, cv2.HISTCMP_CORREL)\n",
    "            if dist > 0.8:\n",
    "                person['last_seen'] = (x, y)\n",
    "                person['missed_frames'] = 0\n",
    "                person['detection_delay'] += 1  # Incrementa o contador de frames para essa pessoa\n",
    "                new_person = False\n",
    "                break\n",
    "\n",
    "        if new_person:\n",
    "            # Adiciona nova pessoa apenas após o número definido de frames\n",
    "            if person_id < DETECTION_DELAY:\n",
    "                person_id += 1\n",
    "                people_detected.append({\n",
    "                    'id': person_id,\n",
    "                    'hist': person_hist,\n",
    "                    'last_seen': (x, y),\n",
    "                    'missed_frames': 0,\n",
    "                    'detection_delay': 1  # Inicia o contador para nova detecção\n",
    "                })\n",
    "                cv2.putText(frame, f\"Pessoa {person_id} detectada\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "            else:\n",
    "                # Se a nova pessoa ainda não tiver sido detectada por um tempo suficiente, apenas atualiza last_seen\n",
    "                cv2.putText(frame, \"Esperando por nova detecção...\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Desenhar a casca convexa ao redor da pessoa detectada\n",
    "        hull = cv2.convexHull(contour)\n",
    "        cv2.drawContours(frame, [hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Atualiza o contador de frames perdidos para todas as pessoas\n",
    "    for person in people_detected:\n",
    "        if person['missed_frames'] > TIMEOUT:\n",
    "            people_detected.remove(person)\n",
    "        else:\n",
    "            person['missed_frames'] += 1\n",
    "\n",
    "    # Mostrar IDs de todas as pessoas detectadas recentemente\n",
    "    for person in people_detected:\n",
    "        if person['missed_frames'] <= TIMEOUT:\n",
    "            cv2.putText(frame, f\"Pessoa {person['id']}\", person['last_seen'], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar o frame com as detecções\n",
    "    cv2.imshow('Deteccao de Mudancas', frame)\n",
    "    cv2.imshow('Thresh', thresh)\n",
    "    cv2.imshow('Frame Delta', frame_delta)\n",
    "\n",
    "    # Pressione 'q' para sair\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar o vídeo e fechar as janelas\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vídeo de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Abrir o vídeo\n",
    "cam = cv2.VideoCapture(\"./teste4.mp4\")\n",
    "\n",
    "# Ler o primeiro frame como referência de fundo\n",
    "ret, frame_reference = cam.read()\n",
    "if not ret:\n",
    "    print(\"Erro ao carregar o vídeo\")\n",
    "    cam.release()\n",
    "    exit()\n",
    "\n",
    "fast = cv2.FastFeatureDetector_create() \n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "frame_reference = cv2.resize(frame_reference, (0, 0), fx=1, fy=1)\n",
    "frame_reference = cv2.flip(frame_reference, 1)\n",
    "frame_reference_gray = cv2.cvtColor(frame_reference, cv2.COLOR_BGR2GRAY)\n",
    "frame_reference_gray = cv2.GaussianBlur(frame_reference_gray, (31, 31), 0)\n",
    "\n",
    "# Inicializar variáveis para histórico de pessoas detectadas\n",
    "people_detected = []\n",
    "person_id = 0\n",
    "false_id = 500000\n",
    "TIMEOUT = 25  # Número de frames até considerarmos que a pessoa saiu\n",
    "DETECTION_DELAY = 100  # Número de frames para considerar uma nova pessoa\n",
    "paused = False\n",
    "\n",
    "# Função para calcular o histograma de cores de um ROI\n",
    "def get_color_histogram(roi):\n",
    "    hist = cv2.calcHist([roi], [0, 1, 2], None, [8, 8, 8], [0, 256, 0, 256, 0, 256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "\n",
    "COLOR_NAMES = {\n",
    "    'preto': (0, 0, 0),\n",
    "    'branco': (255, 255, 255),\n",
    "    'cinza escuro': (64, 64, 64),\n",
    "    'cinza': (128, 128, 128),\n",
    "    'cinza claro': (192, 192, 192),\n",
    "    'vermelho': (255, 0, 0),\n",
    "    'verde': (0, 255, 0),\n",
    "    'azul': (0, 0, 255),\n",
    "    'amarelo': (255, 255, 0),\n",
    "    'ciano': (0, 255, 255),\n",
    "    'magenta': (255, 0, 255),\n",
    "    'laranja': (255, 165, 0),\n",
    "    'rosa': (255, 192, 203),\n",
    "    'roxo': (128, 0, 128),\n",
    "    'marrom': (165, 42, 42),\n",
    "    'azul claro': (173, 216, 230),\n",
    "    'verde claro': (144, 238, 144),\n",
    "    'vermelho claro': (255, 102, 102),\n",
    "    'amarelo claro': (255, 255, 153),\n",
    "    'laranja escuro': (255, 140, 0),\n",
    "    'roxo claro': (216, 191, 216),\n",
    "    'azul escuro': (0, 0, 139),\n",
    "    'verde escuro': (0, 100, 0),\n",
    "    'vermelho escuro': (139, 0, 0),\n",
    "    'dourado': (255, 215, 0),\n",
    "    'prata': (192, 192, 192),\n",
    "    'champanhe': (247, 231, 206),\n",
    "    'violeta': (238, 130, 238),\n",
    "    'salmão': (250, 128, 114),\n",
    "    'menta': (189, 252, 201),\n",
    "    'lavanda': (230, 230, 250),\n",
    "    'azul marinho': (0, 0, 128),\n",
    "    'verde oliva': (107, 142, 35),\n",
    "    'bege': (245, 245, 220),\n",
    "    'turquesa': (64, 224, 208),\n",
    "    'marfim': (255, 255, 240)\n",
    "}\n",
    "\n",
    "# Função para calcular a distância euclidiana entre cores\n",
    "def euclidean_distance(color1, color2):\n",
    "    return np.sqrt(np.sum((np.array(color1) - np.array(color2)) ** 2))\n",
    "\n",
    "# Função para encontrar o nome da cor mais próxima\n",
    "def get_color_name(mean_color):\n",
    "    closest_color = None\n",
    "    min_distance = float('inf')\n",
    "    for color_name, color_value in COLOR_NAMES.items():\n",
    "        dist = euclidean_distance(mean_color[:3], color_value)  # Ignorar o canal alpha (transparência)\n",
    "        if dist < min_distance:\n",
    "            min_distance = dist\n",
    "            closest_color = color_name\n",
    "    return closest_color\n",
    "\n",
    "\n",
    "def get_median_color(roi_contour, mask):\n",
    "    # Extraímos as cores do ROI usando a máscara\n",
    "    roi_colors = roi_contour[mask == 255]  # Pega apenas os pixels dentro da máscara\n",
    "    if roi_colors.size == 0:\n",
    "        return (0, 0, 0)  # Retorna preto se não houver pixels válidos\n",
    "\n",
    "    # Calcula a mediana para cada canal (B, G, R)\n",
    "    median_color = np.median(roi_colors, axis=0)\n",
    "    return median_color\n",
    "\n",
    "while True:\n",
    "    if not paused:\n",
    "        ret, frame = cam.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame = cv2.resize(frame, (0, 0), fx=1, fy=1)\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame_gray = cv2.GaussianBlur(frame_gray, (31, 31), 0)\n",
    "\n",
    "        # Subtrair o frame de referência do frame atual\n",
    "        frame_delta = cv2.absdiff(frame_reference_gray, frame_gray)\n",
    "        _, thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)\n",
    "        thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "        \n",
    "        colored_movement = cv2.bitwise_and(frame, frame, mask=thresh)\n",
    "\n",
    "        # Encontrar contornos\n",
    "        contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        # Filtrar contornos pequenos e criar uma lista de áreas\n",
    "        valid_contours = []\n",
    "        areas = [cv2.contourArea(contour) for contour in contours if cv2.contourArea(contour) >= 1000]\n",
    "\n",
    "        if areas:\n",
    "            max_area = max(areas)\n",
    "\n",
    "            for contour in contours:\n",
    "                area = cv2.contourArea(contour)\n",
    "                if area >= 1000 and area > max_area * 0.3:\n",
    "                    valid_contours.append(contour)\n",
    "\n",
    "        # Loop sobre os contornos filtrados\n",
    "        for contour in valid_contours:\n",
    "            x, y, w, h = cv2.boundingRect(contour)\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            person_hist = get_color_histogram(roi)\n",
    "\n",
    "            new_person = True\n",
    "            for person in people_detected:\n",
    "                dist = cv2.compareHist(person['hist'], person_hist, cv2.HISTCMP_CORREL)\n",
    "                if dist > 0.8:\n",
    "                    person['last_seen'] = (x, y)\n",
    "                    person['missed_frames'] = 0\n",
    "                    person['detection_delay'] += 1  # Incrementa o contador de frames para essa pessoa\n",
    "                    new_person = False\n",
    "                    \n",
    "                    # Se a pessoa já estiver detectada há mais de 3 segundos, capturar keypoints e descritores\n",
    "                    if time.time() - person['time_entered'] > 3:\n",
    "                        if person['false_id'] != 0: \n",
    "                            person_id += 1\n",
    "                            person[\"real_id\"] = person_id\n",
    "                        person['false_id'] = 0\n",
    "\n",
    "                        hull = cv2.convexHull(contour)\n",
    "                        cv2.drawContours(frame, [hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "                        kp = fast.detect(colored_movement, None) \n",
    "                        kp, des = orb.compute(colored_movement, kp) \n",
    "                        person['keypoints'] = kp[:person['num_descriptors']]\n",
    "                        person['descriptors'] = des[:person['num_descriptors']]\n",
    "                        person['num_descriptors'] += 10  # Aumenta o número de descritores capturados\n",
    "\n",
    "                        # Desenhar keypoints na imagem\n",
    "                        cv2.putText(frame, f\"Pessoa {person['real_id']} detectada\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "                    # Adicionar o código para calcular a cor predominante dentro do contorno\n",
    "                    roi_contour = frame[y:y+h, x:x+w]\n",
    "                    mask = np.zeros_like(roi_contour)\n",
    "                    \n",
    "                    cv2.drawContours(mask, [contour], -1, (255, 255, 255), thickness=cv2.FILLED, offset=(-x, -y))\n",
    "                    median_color = get_median_color(roi_contour, mask[:, :, 0])\n",
    "                    median_color = [float(f\"{median_color[0]:.1f}\"), float(f\"{median_color[1]:.1f}\"), float(f\"{median_color[2]:.1f}\")]\n",
    "                    color_name = get_color_name(median_color)\n",
    "                    cv2.putText(frame, f\"Cor: {median_color}\", (x, y - 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                    cv2.putText(frame, f\"Cor: {color_name}\", (x, y + 30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 255), 2)\n",
    "                    \n",
    "                    break\n",
    "\n",
    "            if new_person:\n",
    "                false_id += 1\n",
    "                people_detected.append({\n",
    "                    'false_id': false_id,\n",
    "                    'real_id': false_id,\n",
    "                    'hist': person_hist,\n",
    "                    'last_seen': (x, y),\n",
    "                    'missed_frames': 0,\n",
    "                    'detection_delay': 1,  # Inicia o contador para nova detecção\n",
    "                    'time_entered': time.time(),\n",
    "                    'num_descriptors': 10,  # Inicia com 10 descritores\n",
    "                    'keypoints': None,\n",
    "                    'descriptors': None\n",
    "                })\n",
    "\n",
    "        # Atualiza o contador de frames perdidos para todas as pessoas\n",
    "        for person in people_detected:\n",
    "            if person['missed_frames'] > TIMEOUT:\n",
    "                people_detected.remove(person)\n",
    "            else:\n",
    "                person['missed_frames'] += 1\n",
    "\n",
    "        # Mostrar IDs de todas as pessoas detectadas recentemente\n",
    "        cv2.imshow('Colored', colored_movement)\n",
    "        cv2.imshow('Deteccao de Mudancas', frame)\n",
    "\n",
    "    key = cv2.waitKey(30)\n",
    "    if key == 27:  # Esc key to exit\n",
    "        break\n",
    "    elif key == ord('p'):  # Pause\n",
    "        paused = True\n",
    "    elif key == ord('o'):  # Continue\n",
    "        paused = False\n",
    "\n",
    "# Liberar o vídeo e fechar as janelas\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
