{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Abrir \n",
    "cam = cv2.VideoCapture(0)\n",
    "\n",
    "# Ler o primeiro frame como referência de fundo\n",
    "ret, frame_reference = cam.read()\n",
    "if not ret:\n",
    "    print(\"Erro ao carregar o vídeo\")\n",
    "    cam.release()\n",
    "    exit()\n",
    "\n",
    "frame_reference = cv2.resize(frame_reference, (0, 0), fx=1.15, fy=1.15)\n",
    "frame_reference = cv2.flip(frame_reference, 1)\n",
    "frame_reference_gray = cv2.cvtColor(frame_reference, cv2.COLOR_BGR2GRAY)\n",
    "frame_reference_gray = cv2.GaussianBlur(frame_reference_gray, (31, 31), 0)\n",
    "\n",
    "# Inicializar variáveis para histórico de pessoas detectadas\n",
    "people_detected = []\n",
    "person_id = 0\n",
    "TIMEOUT = 50  # Número de frames até considerarmos que a pessoa saiu\n",
    "DETECTION_DELAY = 200  # Número de frames para considerar uma nova pessoa\n",
    "\n",
    "# Inicializar o detector ORB\n",
    "orb = cv2.ORB_create()\n",
    "\n",
    "# Função para detectar e descrever as features do ROI\n",
    "def get_features(roi):\n",
    "    keypoints, descriptors = orb.detectAndCompute(roi, None)\n",
    "    return keypoints, descriptors\n",
    "\n",
    "# Inicializar o Brute Force Matcher\n",
    "bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cam.read()\n",
    "\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = cv2.flip(frame, 1)\n",
    "    frame = cv2.resize(frame, (0, 0), fx=1.15, fy=1.15)\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    frame_gray = cv2.GaussianBlur(frame_gray, (31, 31), 0)\n",
    "\n",
    "    # Subtrair o frame de referência do frame atual\n",
    "    frame_delta = cv2.absdiff(frame_reference_gray, frame_gray)\n",
    "    _, thresh = cv2.threshold(frame_delta, 25, 255, cv2.THRESH_BINARY)\n",
    "    thresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\n",
    "    # Encontrar contornos\n",
    "    contours, _ = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Filtrar contornos pequenos e criar uma lista de áreas\n",
    "    valid_contours = []\n",
    "    areas = [cv2.contourArea(contour) for contour in contours if cv2.contourArea(contour) >= 500]\n",
    "\n",
    "    if areas:\n",
    "        max_area = max(areas)\n",
    "\n",
    "        for contour in contours:\n",
    "            area = cv2.contourArea(contour)\n",
    "            if area >= 500 and area > max_area * 0.3:\n",
    "                valid_contours.append(contour)\n",
    "\n",
    "    # Loop sobre os contornos filtrados\n",
    "    for contour in valid_contours:\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        roi = frame[y:y+h, x:x+w]\n",
    "        roi_gray = frame_gray[y:y+h, x:x+w]\n",
    "\n",
    "        # Extrair keypoints e descritores das features\n",
    "        keypoints, descriptors = get_features(roi_gray)\n",
    "\n",
    "        if descriptors is not None:\n",
    "            new_person = True\n",
    "\n",
    "            for person in people_detected:\n",
    "                # Comparar as features usando BFMatcher\n",
    "                matches = bf.match(person['descriptors'], descriptors)\n",
    "                matches = sorted(matches, key=lambda x: x.distance)\n",
    "\n",
    "                # Se houver um número suficiente de correspondências, consideramos a pessoa como já detectada\n",
    "                if len(matches) > 10:  # Valor arbitrário, pode ser ajustado\n",
    "                    person['last_seen'] = (x, y)\n",
    "                    person['missed_frames'] = 0\n",
    "                    person['detection_delay'] += 1\n",
    "                    new_person = False\n",
    "                    break\n",
    "\n",
    "            if new_person:\n",
    "                # Adiciona nova pessoa após DETECTION_DELAY frames\n",
    "                if person_id < DETECTION_DELAY:\n",
    "                    person_id += 1\n",
    "                    people_detected.append({\n",
    "                        'id': person_id,\n",
    "                        'descriptors': descriptors,\n",
    "                        'last_seen': (x, y),\n",
    "                        'missed_frames': 0,\n",
    "                        'detection_delay': 1  # Inicia o contador para nova detecção\n",
    "                    })\n",
    "                    cv2.putText(frame, f\"Pessoa {person_id} detectada\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "                else:\n",
    "                    cv2.putText(frame, \"Esperando por nova detecção...\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "        # Desenhar a casca convexa ao redor da pessoa detectada\n",
    "        hull = cv2.convexHull(contour)\n",
    "        cv2.drawContours(frame, [hull], -1, (0, 255, 0), 2)\n",
    "\n",
    "    # Atualiza o contador de frames perdidos para todas as pessoas\n",
    "    for person in people_detected:\n",
    "        if person['missed_frames'] > TIMEOUT:\n",
    "            people_detected.remove(person)\n",
    "        else:\n",
    "            person['missed_frames'] += 1\n",
    "\n",
    "    # Mostrar IDs de todas as pessoas detectadas recentemente\n",
    "    for person in people_detected:\n",
    "        if person['missed_frames'] <= TIMEOUT:\n",
    "            cv2.putText(frame, f\"Pessoa {person['id']}\", person['last_seen'], cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Mostrar o frame com as detecções\n",
    "    cv2.imshow('Deteccao de Mudancas', frame)\n",
    "    cv2.imshow('Thresh', thresh)\n",
    "    cv2.imshow('Frame Delta', frame_delta)\n",
    "\n",
    "    # Pressione 'q' para sair\n",
    "    if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Liberar o vídeo e fechar as janelas\n",
    "cam.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
